{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HeteroGAT Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.nn import GATConv, HeteroConv, Linear\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src import temporal_loader_v2 as tl\n",
    "from src.utils import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 1\n",
    "pyg.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv, HeteroConv, Linear\n",
    "\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                edge_type: GATConv((-1,-1), hidden_channels)\n",
    "                for edge_type in metadata[1]\n",
    "            })\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
    "        return self.lin(x_dict['domain_node'])\n",
    "    \n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['domain_node'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['domain_node'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for split in ['train_mask', 'val_mask']:\n",
    "        mask = data['domain_node'][split]\n",
    "        acc = (pred[mask] == data['domain_node'].y[mask]).sum() / mask.sum()\n",
    "        accs.append(float(acc))\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled 897635\n",
      "Labeled node count for 0, 6: 31778\n",
      "Labeled node count for 0, 7: 2610\n",
      "Labeled node count for 0, 8: 2083\n",
      "Epoch: 000, Loss: 0.6810, Train: 0.6810, Val: 0.6810\n",
      "Epoch: 020, Loss: 0.4557, Train: 0.7881, Val: 0.7910\n",
      "Epoch: 040, Loss: 0.4062, Train: 0.8088, Val: 0.8082\n",
      "Epoch: 060, Loss: 0.3968, Train: 0.8101, Val: 0.8105\n",
      "Epoch: 080, Loss: 0.3925, Train: 0.8122, Val: 0.8137\n",
      "Epoch: 100, Loss: 0.3893, Train: 0.8135, Val: 0.8118\n",
      "Epoch: 120, Loss: 0.3875, Train: 0.8146, Val: 0.8148\n",
      "Epoch: 140, Loss: 0.3869, Train: 0.8140, Val: 0.8129\n",
      "Epoch: 160, Loss: 0.3850, Train: 0.8150, Val: 0.8135\n",
      "Epoch: 180, Loss: 0.3854, Train: 0.8153, Val: 0.8093\n",
      "Epoch: 200, Loss: 0.3833, Train: 0.8142, Val: 0.8143\n",
      "tn, fp, fn, tp 1339 266 162 843\n",
      "acc :0.8360\n",
      "f1 :0.8373\n",
      "auc :0.8365\n",
      "prec :0.7601\n",
      "recall :0.8388\n",
      "fpr :0.1657\n",
      "mi_f1 :0.8360\n",
      "ma_f1 :0.8299\n",
      "tn, fp, fn, tp 1092 217 143 631\n",
      "acc :0.8272\n",
      "f1 :0.8286\n",
      "auc :0.8247\n",
      "prec :0.7441\n",
      "recall :0.8152\n",
      "fpr :0.1658\n",
      "mi_f1 :0.8272\n",
      "ma_f1 :0.8183\n",
      "Total labeled 897635\n",
      "Labeled node count for 1, 7: 32913\n",
      "Labeled node count for 1, 8: 2164\n",
      "Labeled node count for 1, 9: 2756\n",
      "Epoch: 000, Loss: 0.7049, Train: 0.6411, Val: 0.6276\n",
      "Epoch: 020, Loss: 0.4575, Train: 0.7835, Val: 0.7812\n",
      "Epoch: 040, Loss: 0.4052, Train: 0.8097, Val: 0.8014\n",
      "Epoch: 060, Loss: 0.3947, Train: 0.8126, Val: 0.8051\n",
      "Epoch: 080, Loss: 0.3898, Train: 0.8145, Val: 0.8067\n",
      "Epoch: 100, Loss: 0.3858, Train: 0.8163, Val: 0.8070\n",
      "Epoch: 120, Loss: 0.3837, Train: 0.8157, Val: 0.8098\n",
      "Epoch: 140, Loss: 0.3832, Train: 0.8169, Val: 0.8064\n",
      "Epoch: 160, Loss: 0.3818, Train: 0.8174, Val: 0.8070\n",
      "Epoch: 180, Loss: 0.3810, Train: 0.8174, Val: 0.8066\n",
      "Epoch: 200, Loss: 0.3809, Train: 0.8160, Val: 0.8084\n",
      "tn, fp, fn, tp 1116 223 138 687\n",
      "acc :0.8332\n",
      "f1 :0.8345\n",
      "auc :0.8331\n",
      "prec :0.7549\n",
      "recall :0.8327\n",
      "fpr :0.1665\n",
      "mi_f1 :0.8332\n",
      "ma_f1 :0.8264\n",
      "tn, fp, fn, tp 1193 224 237 1102\n",
      "acc :0.8327\n",
      "f1 :0.8327\n",
      "auc :0.8325\n",
      "prec :0.8311\n",
      "recall :0.8230\n",
      "fpr :0.1581\n",
      "mi_f1 :0.8327\n",
      "ma_f1 :0.8325\n",
      "Total labeled 897635\n",
      "Labeled node count for 2, 8: 33022\n",
      "Labeled node count for 2, 9: 2878\n",
      "Labeled node count for 2, 10: 1831\n",
      "Epoch: 000, Loss: 0.7213, Train: 0.6516, Val: 0.6485\n",
      "Epoch: 020, Loss: 0.4607, Train: 0.7849, Val: 0.7913\n",
      "Epoch: 040, Loss: 0.4077, Train: 0.8056, Val: 0.8112\n",
      "Epoch: 060, Loss: 0.3965, Train: 0.8082, Val: 0.8131\n",
      "Epoch: 080, Loss: 0.3929, Train: 0.8108, Val: 0.8141\n",
      "Epoch: 100, Loss: 0.3904, Train: 0.8117, Val: 0.8137\n",
      "Epoch: 120, Loss: 0.3890, Train: 0.8115, Val: 0.8142\n",
      "Epoch: 140, Loss: 0.3875, Train: 0.8125, Val: 0.8160\n",
      "Epoch: 160, Loss: 0.3866, Train: 0.8142, Val: 0.8160\n",
      "Epoch: 180, Loss: 0.3850, Train: 0.8140, Val: 0.8169\n",
      "Epoch: 200, Loss: 0.3842, Train: 0.8149, Val: 0.8174\n",
      "tn, fp, fn, tp 1280 212 248 1138\n",
      "acc :0.8402\n",
      "f1 :0.8401\n",
      "auc :0.8395\n",
      "prec :0.8430\n",
      "recall :0.8211\n",
      "fpr :0.1421\n",
      "mi_f1 :0.8402\n",
      "ma_f1 :0.8398\n",
      "tn, fp, fn, tp 834 141 132 724\n",
      "acc :0.8509\n",
      "f1 :0.8509\n",
      "auc :0.8506\n",
      "prec :0.8370\n",
      "recall :0.8458\n",
      "fpr :0.1446\n",
      "mi_f1 :0.8509\n",
      "ma_f1 :0.8504\n",
      "Total labeled 897635\n",
      "Labeled node count for 3, 9: 33643\n",
      "Labeled node count for 3, 10: 1906\n",
      "Labeled node count for 3, 11: 1460\n",
      "Epoch: 000, Loss: 0.6924, Train: 0.7063, Val: 0.7059\n",
      "Epoch: 020, Loss: 0.4574, Train: 0.7874, Val: 0.7751\n",
      "Epoch: 040, Loss: 0.4014, Train: 0.8107, Val: 0.7961\n",
      "Epoch: 060, Loss: 0.3923, Train: 0.8128, Val: 0.7998\n",
      "Epoch: 080, Loss: 0.3877, Train: 0.8148, Val: 0.8016\n",
      "Epoch: 100, Loss: 0.3858, Train: 0.8168, Val: 0.8023\n",
      "Epoch: 120, Loss: 0.3810, Train: 0.8167, Val: 0.8047\n",
      "Epoch: 140, Loss: 0.3789, Train: 0.8179, Val: 0.8048\n",
      "Epoch: 160, Loss: 0.3771, Train: 0.8186, Val: 0.8057\n",
      "Epoch: 180, Loss: 0.3759, Train: 0.8195, Val: 0.8057\n",
      "Epoch: 200, Loss: 0.3762, Train: 0.8183, Val: 0.8066\n",
      "tn, fp, fn, tp 867 136 144 759\n",
      "acc :0.8531\n",
      "f1 :0.8531\n",
      "auc :0.8525\n",
      "prec :0.8480\n",
      "recall :0.8405\n",
      "fpr :0.1356\n",
      "mi_f1 :0.8531\n",
      "ma_f1 :0.8526\n",
      "tn, fp, fn, tp 797 128 95 440\n",
      "acc :0.8473\n",
      "f1 :0.8482\n",
      "auc :0.8420\n",
      "prec :0.7746\n",
      "recall :0.8224\n",
      "fpr :0.1384\n",
      "mi_f1 :0.8473\n",
      "ma_f1 :0.8375\n",
      "Total labeled 897635\n",
      "Labeled node count for 4, 10: 32652\n",
      "Labeled node count for 4, 11: 1530\n",
      "Labeled node count for 4, 12: 2044\n",
      "Epoch: 000, Loss: 0.6838, Train: 0.7131, Val: 0.7155\n",
      "Epoch: 020, Loss: 0.4608, Train: 0.7811, Val: 0.7822\n",
      "Epoch: 040, Loss: 0.4022, Train: 0.8102, Val: 0.8149\n",
      "Epoch: 060, Loss: 0.3935, Train: 0.8131, Val: 0.8168\n",
      "Epoch: 080, Loss: 0.3878, Train: 0.8139, Val: 0.8179\n",
      "Epoch: 100, Loss: 0.3847, Train: 0.8143, Val: 0.8173\n",
      "Epoch: 120, Loss: 0.3827, Train: 0.8156, Val: 0.8176\n",
      "Epoch: 140, Loss: 0.3816, Train: 0.8156, Val: 0.8175\n",
      "Epoch: 160, Loss: 0.3815, Train: 0.8159, Val: 0.8161\n",
      "Epoch: 180, Loss: 0.3795, Train: 0.8155, Val: 0.8173\n",
      "Epoch: 200, Loss: 0.3787, Train: 0.8167, Val: 0.8188\n",
      "tn, fp, fn, tp 803 156 90 481\n",
      "acc :0.8392\n",
      "f1 :0.8407\n",
      "auc :0.8399\n",
      "prec :0.7551\n",
      "recall :0.8424\n",
      "fpr :0.1627\n",
      "mi_f1 :0.8392\n",
      "ma_f1 :0.8318\n",
      "tn, fp, fn, tp 977 179 175 713\n",
      "acc :0.8268\n",
      "f1 :0.8269\n",
      "auc :0.8240\n",
      "prec :0.7993\n",
      "recall :0.8029\n",
      "fpr :0.1548\n",
      "mi_f1 :0.8268\n",
      "ma_f1 :0.8239\n"
     ]
    }
   ],
   "source": [
    "def experiment(start,end,test_list, model_type):\n",
    "    kg_path = lambda graph_name: f'../data/{graph_name}'\n",
    "\n",
    "    dataset = tl.DNS(root=kg_path('DNS_2m'), start=start, end=end, test_list=test_list, balance_gt=False, domain_file='domains2.csv')\n",
    "    data = dataset.train_data # training data\n",
    "    \n",
    "    model = HeteroGNN(data.metadata(), hidden_channels=64, out_channels=2, num_layers=2)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        torch.cuda.set_device(cuda_device)\n",
    "\n",
    "        data, model = data.to(device), model.to(device)\n",
    "\n",
    "    with torch.no_grad():  # Initialize lazy modules.\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "    for epoch in range(0, 201):\n",
    "        loss = train(model, data, optimizer)\n",
    "        train_acc, val_acc = test(model,data)\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
    "                f'Val: {val_acc:.4f}')\n",
    "        \n",
    "    model.eval()\n",
    "    for index, test_data in enumerate(dataset.test_data):\n",
    "        test_data = test_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(test_data.x_dict, test_data.edge_index_dict).argmax(dim=-1)\n",
    "        mask = test_data['domain_node']['val_mask']\n",
    "        scores = score(pred[mask],test_data['domain_node'].y[mask])\n",
    "        with open(\"../results_copy.csv\", \"a\") as logger:\n",
    "            logger.write(\"{},{},{},{},\".format(model_type,start,end,index))\n",
    "            logger.write(\",\".join(str(x) for x in scores.values()))\n",
    "            logger.write('\\n')\n",
    "\n",
    "\n",
    "        for metric, val in scores.items():\n",
    "            print(metric, ':{:.4f}'.format(val))\n",
    "    \n",
    "for model_type in ['heterogat']:\n",
    "    for i in range(5):\n",
    "        experiment(i,i+6,[i+7,i+8], model_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
