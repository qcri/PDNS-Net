{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DNS and mDNS datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import src.temporal_loader_v2 as tl\n",
    "from src.utils import to_homogeneous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8c30953790>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_device = 4\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "    \n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled 897635\n",
      "Labeled node count for 0, 6: 31778\n",
      "After balancing labeled count: 31282\n",
      "Labeled node count for 0, 7: 2610\n"
     ]
    }
   ],
   "source": [
    "kg_path = lambda graph_name: f'../data/{graph_name}'\n",
    "dataset = tl.DNS(root=kg_path('DNS_2m'), start=0, end=6, test_list=[7], balance_gt=True, domain_file='domains2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1173558, 12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = to_homogeneous(dataset.train_data) # training data\n",
    "# test_data = to_homogeneous(dataset.test_data[0])\n",
    "data.x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import RGCNConv, Linear\n",
    "\n",
    "\n",
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, dim=16, num_classes=2, num_layers=2):\n",
    "        super(RGCN, self).__init__()\n",
    "\n",
    "        self.conv1 = RGCNConv(num_features, dim, num_relations=3)\n",
    "        self.gcs = nn.ModuleList()\n",
    "        self.num_layers = num_layers\n",
    "        for i in range(1, num_layers):\n",
    "            conv = RGCNConv(dim, dim, num_relations=3) \n",
    "            self.gcs.append(conv)\n",
    "        self.lin = Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_type))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        for i in range(1, self.num_layers):\n",
    "            x = F.relu(self.gcs[i-1](x, edge_index, edge_type))\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled 897635\n",
      "Labeled node count for 0, 6: 31778\n",
      "Labeled node count for 0, 7: 2610\n",
      "Labeled node count for 0, 8: 2083\n",
      "Epoch: 000, Loss: 0.7034, Train: 0.6604, Val: 0.6658\n",
      "Epoch: 020, Loss: 0.4749, Train: 0.7666, Val: 0.7739\n",
      "Epoch: 040, Loss: 0.4318, Train: 0.8123, Val: 0.8179\n",
      "Epoch: 060, Loss: 0.4089, Train: 0.8176, Val: 0.8225\n",
      "Epoch: 080, Loss: 0.3960, Train: 0.8206, Val: 0.8228\n",
      "Epoch: 100, Loss: 0.3929, Train: 0.8208, Val: 0.8198\n",
      "Epoch: 120, Loss: 0.3893, Train: 0.8226, Val: 0.8195\n",
      "Epoch: 140, Loss: 0.3875, Train: 0.8224, Val: 0.8201\n",
      "Epoch: 160, Loss: 0.3873, Train: 0.8230, Val: 0.8228\n",
      "Epoch: 180, Loss: 0.3855, Train: 0.8225, Val: 0.8206\n",
      "Epoch: 200, Loss: 0.3866, Train: 0.8239, Val: 0.8212\n",
      "tn, fp, fn, tp 1318 287 127 878\n",
      "acc :0.8414\n",
      "f1 :0.8431\n",
      "auc :0.8474\n",
      "prec :0.7536\n",
      "recall :0.8736\n",
      "fpr :0.1788\n",
      "mi_f1 :0.8414\n",
      "ma_f1 :0.8367\n",
      "tn, fp, fn, tp 1072 237 114 660\n",
      "acc :0.8315\n",
      "f1 :0.8335\n",
      "auc :0.8358\n",
      "prec :0.7358\n",
      "recall :0.8527\n",
      "fpr :0.1811\n",
      "mi_f1 :0.8315\n",
      "ma_f1 :0.8246\n",
      "Total labeled 897635\n",
      "Labeled node count for 1, 7: 32913\n",
      "Labeled node count for 1, 8: 2164\n",
      "Labeled node count for 1, 9: 2756\n",
      "Epoch: 000, Loss: 0.6923, Train: 0.7534, Val: 0.7505\n",
      "Epoch: 020, Loss: 0.4716, Train: 0.7714, Val: 0.7685\n",
      "Epoch: 040, Loss: 0.4368, Train: 0.8038, Val: 0.8019\n",
      "Epoch: 060, Loss: 0.4135, Train: 0.8157, Val: 0.8156\n",
      "Epoch: 080, Loss: 0.3981, Train: 0.8216, Val: 0.8183\n",
      "Epoch: 100, Loss: 0.3909, Train: 0.8221, Val: 0.8189\n",
      "Epoch: 120, Loss: 0.3885, Train: 0.8221, Val: 0.8204\n",
      "Epoch: 140, Loss: 0.3855, Train: 0.8224, Val: 0.8209\n",
      "Epoch: 160, Loss: 0.3854, Train: 0.8223, Val: 0.8206\n",
      "Epoch: 180, Loss: 0.3837, Train: 0.8221, Val: 0.8203\n",
      "Epoch: 200, Loss: 0.3810, Train: 0.8229, Val: 0.8219\n",
      "tn, fp, fn, tp 1107 232 122 703\n",
      "acc :0.8364\n",
      "f1 :0.8380\n",
      "auc :0.8394\n",
      "prec :0.7519\n",
      "recall :0.8521\n",
      "fpr :0.1733\n",
      "mi_f1 :0.8364\n",
      "ma_f1 :0.8305\n",
      "tn, fp, fn, tp 1190 227 178 1161\n",
      "acc :0.8530\n",
      "f1 :0.8531\n",
      "auc :0.8534\n",
      "prec :0.8365\n",
      "recall :0.8671\n",
      "fpr :0.1602\n",
      "mi_f1 :0.8530\n",
      "ma_f1 :0.8530\n",
      "Total labeled 897635\n",
      "Labeled node count for 2, 8: 33022\n",
      "Labeled node count for 2, 9: 2878\n",
      "Labeled node count for 2, 10: 1831\n",
      "Epoch: 000, Loss: 0.7051, Train: 0.6890, Val: 0.6944\n",
      "Epoch: 020, Loss: 0.4782, Train: 0.7683, Val: 0.7770\n",
      "Epoch: 040, Loss: 0.4377, Train: 0.8109, Val: 0.8178\n",
      "Epoch: 060, Loss: 0.4105, Train: 0.8175, Val: 0.8248\n",
      "Epoch: 080, Loss: 0.4005, Train: 0.8187, Val: 0.8247\n",
      "Epoch: 100, Loss: 0.3924, Train: 0.8202, Val: 0.8269\n",
      "Epoch: 120, Loss: 0.3890, Train: 0.8204, Val: 0.8266\n",
      "Epoch: 140, Loss: 0.3877, Train: 0.8203, Val: 0.8269\n",
      "Epoch: 160, Loss: 0.3852, Train: 0.8208, Val: 0.8275\n",
      "Epoch: 180, Loss: 0.3843, Train: 0.8213, Val: 0.8280\n",
      "Epoch: 200, Loss: 0.3811, Train: 0.8210, Val: 0.8277\n",
      "tn, fp, fn, tp 1252 240 191 1195\n",
      "acc :0.8502\n",
      "f1 :0.8503\n",
      "auc :0.8507\n",
      "prec :0.8328\n",
      "recall :0.8622\n",
      "fpr :0.1609\n",
      "mi_f1 :0.8502\n",
      "ma_f1 :0.8502\n",
      "tn, fp, fn, tp 827 148 110 746\n",
      "acc :0.8591\n",
      "f1 :0.8592\n",
      "auc :0.8599\n",
      "prec :0.8345\n",
      "recall :0.8715\n",
      "fpr :0.1518\n",
      "mi_f1 :0.8591\n",
      "ma_f1 :0.8588\n",
      "Total labeled 897635\n",
      "Labeled node count for 3, 9: 33643\n",
      "Labeled node count for 3, 10: 1906\n",
      "Labeled node count for 3, 11: 1460\n",
      "Epoch: 000, Loss: 0.6864, Train: 0.7268, Val: 0.7094\n",
      "Epoch: 020, Loss: 0.4588, Train: 0.7853, Val: 0.7886\n",
      "Epoch: 040, Loss: 0.4267, Train: 0.8176, Val: 0.8118\n",
      "Epoch: 060, Loss: 0.4029, Train: 0.8226, Val: 0.8127\n",
      "Epoch: 080, Loss: 0.3921, Train: 0.8251, Val: 0.8124\n",
      "Epoch: 100, Loss: 0.3857, Train: 0.8260, Val: 0.8139\n",
      "Epoch: 120, Loss: 0.3835, Train: 0.8267, Val: 0.8151\n",
      "Epoch: 140, Loss: 0.3804, Train: 0.8260, Val: 0.8136\n",
      "Epoch: 160, Loss: 0.3798, Train: 0.8276, Val: 0.8150\n",
      "Epoch: 180, Loss: 0.3788, Train: 0.8278, Val: 0.8154\n",
      "Epoch: 200, Loss: 0.3777, Train: 0.8279, Val: 0.8139\n",
      "tn, fp, fn, tp 835 168 110 793\n",
      "acc :0.8541\n",
      "f1 :0.8542\n",
      "auc :0.8553\n",
      "prec :0.8252\n",
      "recall :0.8782\n",
      "fpr :0.1675\n",
      "mi_f1 :0.8541\n",
      "ma_f1 :0.8541\n",
      "tn, fp, fn, tp 763 162 71 464\n",
      "acc :0.8404\n",
      "f1 :0.8425\n",
      "auc :0.8461\n",
      "prec :0.7412\n",
      "recall :0.8673\n",
      "fpr :0.1751\n",
      "mi_f1 :0.8404\n",
      "ma_f1 :0.8334\n",
      "Total labeled 897635\n",
      "Labeled node count for 4, 10: 32652\n",
      "Labeled node count for 4, 11: 1530\n",
      "Labeled node count for 4, 12: 2044\n",
      "Epoch: 000, Loss: 0.6998, Train: 0.5726, Val: 0.5841\n",
      "Epoch: 020, Loss: 0.4691, Train: 0.7796, Val: 0.7809\n",
      "Epoch: 040, Loss: 0.4308, Train: 0.8166, Val: 0.8207\n",
      "Epoch: 060, Loss: 0.4075, Train: 0.8196, Val: 0.8247\n",
      "Epoch: 080, Loss: 0.3939, Train: 0.8216, Val: 0.8260\n",
      "Epoch: 100, Loss: 0.3890, Train: 0.8231, Val: 0.8282\n",
      "Epoch: 120, Loss: 0.3857, Train: 0.8244, Val: 0.8280\n",
      "Epoch: 140, Loss: 0.3833, Train: 0.8251, Val: 0.8292\n",
      "Epoch: 160, Loss: 0.3807, Train: 0.8254, Val: 0.8286\n",
      "Epoch: 180, Loss: 0.3775, Train: 0.8256, Val: 0.8282\n",
      "Epoch: 200, Loss: 0.3787, Train: 0.8249, Val: 0.8292\n",
      "tn, fp, fn, tp 797 162 75 496\n",
      "acc :0.8451\n",
      "f1 :0.8469\n",
      "auc :0.8499\n",
      "prec :0.7538\n",
      "recall :0.8687\n",
      "fpr :0.1689\n",
      "mi_f1 :0.8451\n",
      "ma_f1 :0.8389\n",
      "tn, fp, fn, tp 969 187 147 741\n",
      "acc :0.8366\n",
      "f1 :0.8370\n",
      "auc :0.8363\n",
      "prec :0.7985\n",
      "recall :0.8345\n",
      "fpr :0.1618\n",
      "mi_f1 :0.8366\n",
      "ma_f1 :0.8345\n"
     ]
    }
   ],
   "source": [
    "cuda_device = 1\n",
    "torch.manual_seed(42)\n",
    "from src.utils import score\n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.edge_type)\n",
    "    mask = data.train_mask\n",
    "    loss = F.cross_entropy(out[mask], data.y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    pred = model(data.x, data.edge_index, data.edge_type).argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for split in ['train_mask', 'val_mask']:\n",
    "        mask = data[split]\n",
    "        acc = (pred[mask] == data.y[mask]).sum() / mask.sum()\n",
    "        accs.append(float(acc))\n",
    "    return accs\n",
    "\n",
    "def experiment(model,start,end,test_list, model_type):\n",
    "    kg_path = lambda graph_name: f'../data/{graph_name}'\n",
    "\n",
    "    dataset = tl.DNS(root=kg_path('DNS_2m'), start=start, end=end, test_list=test_list, balance_gt=False, domain_file='domains2.csv')\n",
    "    data = to_homogeneous(dataset.train_data) # training data\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        torch.cuda.set_device(cuda_device)\n",
    "\n",
    "        data, model = data.to(device), model.to(device)\n",
    "\n",
    "    with torch.no_grad():  # Initialize lazy modules.\n",
    "        out = model(data.x, data.edge_index, data.edge_type)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "    for epoch in range(0, 201):\n",
    "        loss = train(model, data, optimizer)\n",
    "        train_acc, val_acc = test(model,data)\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
    "                f'Val: {val_acc:.4f}')\n",
    "        \n",
    "    model.eval()\n",
    "    for index, test_data in enumerate(dataset.test_data):\n",
    "        test_data = to_homogeneous(test_data)\n",
    "        test_data = test_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(test_data.x, test_data.edge_index, test_data.edge_type).argmax(dim=-1)\n",
    "        mask = test_data['val_mask']\n",
    "        scores = score(pred[mask],test_data.y[mask])\n",
    "        with open(\"../results_copy.csv\", \"a\") as logger:\n",
    "            logger.write(\"{},{},{},{},\".format(model_type,start,end,index))\n",
    "            logger.write(\",\".join(str(x) for x in scores.values()))\n",
    "            logger.write('\\n')\n",
    "\n",
    "\n",
    "        for metric, val in scores.items():\n",
    "            print(metric, ':{:.4f}'.format(val))\n",
    "    \n",
    "for model_type in ['rgcn']:\n",
    "    for i in range(5):\n",
    "        # model_type='gcn'  \n",
    "        data.x.size(1) \n",
    "        model = RGCN(data.x.size(1), dim=64, num_classes=2,\n",
    "                  num_layers=2)\n",
    "        experiment(model,i,i+6,[i+7,i+8], model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
