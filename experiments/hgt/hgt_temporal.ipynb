{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DNS and mDNS datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import src.temporal_loader_v2 as tl\n",
    "from src.utils import to_homogeneous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f823441a790>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_device = 4\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "    \n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled 897635\n",
      "Labeled node count for 0, 6: 31778\n",
      "After balancing labeled count: 31282\n",
      "Labeled node count for 0, 7: 2610\n"
     ]
    }
   ],
   "source": [
    "kg_path = lambda graph_name: f'../../data/{graph_name}'\n",
    "dataset = tl.DNS(root=kg_path('DNS_2m'), start=0, end=6, test_list=[7], balance_gt=True, domain_file='domains2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['domain_node', 'ip_node'],\n",
       " [('domain_node', 'apex', 'domain_node'),\n",
       "  ('domain_node', 'resolves', 'ip_node'),\n",
       "  ('domain_node', 'similar', 'domain_node')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.train_data # training data\n",
    "# data = to_homogeneous(dataset.train_data) # training data\n",
    "# test_data = to_homogeneous(dataset.test_data[0])\n",
    "dataset.train_data.metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import Linear\n",
    "from hgt_conv import HGTConv\n",
    "\n",
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, data, hidden_channels, out_channels, num_heads, num_layers, num_features=-1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in data.node_types:\n",
    "            self.lin_dict[node_type] = Linear(num_features, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(),\n",
    "                           num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, target_nodetype='domain_node'):\n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return self.lin(x_dict[target_nodetype])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled 897635\n",
      "Labeled node count for 0, 6: 31778\n",
      "Labeled node count for 0, 7: 2610\n",
      "Labeled node count for 0, 8: 2083\n",
      "Epoch: 000, Loss: 0.6959, Train: 0.5134, Val: 0.5194\n",
      "Epoch: 020, Loss: 0.5720, Train: 0.7262, Val: 0.7223\n",
      "Epoch: 040, Loss: 0.5300, Train: 0.7676, Val: 0.7613\n",
      "Epoch: 060, Loss: 0.4711, Train: 0.7658, Val: 0.7583\n",
      "Epoch: 080, Loss: 0.4396, Train: 0.7883, Val: 0.7789\n",
      "Epoch: 100, Loss: 0.4278, Train: 0.8031, Val: 0.7929\n",
      "Epoch: 120, Loss: 0.4188, Train: 0.8058, Val: 0.7959\n",
      "Epoch: 140, Loss: 0.4102, Train: 0.8124, Val: 0.8028\n",
      "Epoch: 160, Loss: 0.4023, Train: 0.8169, Val: 0.8101\n",
      "Epoch: 180, Loss: 0.3959, Train: 0.8173, Val: 0.8107\n",
      "Epoch: 200, Loss: 0.3908, Train: 0.8182, Val: 0.8101\n",
      "tn, fp, fn, tp 1369 236 175 830\n",
      "acc :0.8425\n",
      "f1 :0.8433\n",
      "auc :0.8394\n",
      "prec :0.7786\n",
      "recall :0.8259\n",
      "fpr :0.1470\n",
      "mi_f1 :0.8425\n",
      "ma_f1 :0.8355\n",
      "tn, fp, fn, tp 1122 187 150 624\n",
      "acc :0.8382\n",
      "f1 :0.8389\n",
      "auc :0.8317\n",
      "prec :0.7694\n",
      "recall :0.8062\n",
      "fpr :0.1429\n",
      "mi_f1 :0.8382\n",
      "ma_f1 :0.8284\n",
      "Total labeled 897635\n",
      "Labeled node count for 1, 7: 32913\n",
      "Labeled node count for 1, 8: 2164\n",
      "Labeled node count for 1, 9: 2756\n",
      "Epoch: 000, Loss: 0.7068, Train: 0.4845, Val: 0.4857\n",
      "Epoch: 020, Loss: 0.5757, Train: 0.7006, Val: 0.6931\n",
      "Epoch: 040, Loss: 0.5340, Train: 0.7689, Val: 0.7648\n",
      "Epoch: 060, Loss: 0.4725, Train: 0.7702, Val: 0.7680\n",
      "Epoch: 080, Loss: 0.4381, Train: 0.7739, Val: 0.7710\n",
      "Epoch: 100, Loss: 0.4277, Train: 0.7982, Val: 0.7909\n",
      "Epoch: 120, Loss: 0.4197, Train: 0.8041, Val: 0.7958\n",
      "Epoch: 140, Loss: 0.4121, Train: 0.8106, Val: 0.8054\n",
      "Epoch: 160, Loss: 0.4047, Train: 0.8139, Val: 0.8090\n",
      "Epoch: 180, Loss: 0.3980, Train: 0.8174, Val: 0.8124\n",
      "Epoch: 200, Loss: 0.3924, Train: 0.8185, Val: 0.8112\n",
      "tn, fp, fn, tp 1162 177 171 654\n",
      "acc :0.8392\n",
      "f1 :0.8393\n",
      "auc :0.8303\n",
      "prec :0.7870\n",
      "recall :0.7927\n",
      "fpr :0.1322\n",
      "mi_f1 :0.8392\n",
      "ma_f1 :0.8298\n",
      "tn, fp, fn, tp 1247 170 250 1089\n",
      "acc :0.8476\n",
      "f1 :0.8474\n",
      "auc :0.8467\n",
      "prec :0.8650\n",
      "recall :0.8133\n",
      "fpr :0.1200\n",
      "mi_f1 :0.8476\n",
      "ma_f1 :0.8471\n",
      "Total labeled 897635\n",
      "Labeled node count for 2, 8: 33022\n",
      "Labeled node count for 2, 9: 2878\n",
      "Labeled node count for 2, 10: 1831\n",
      "Epoch: 000, Loss: 0.6941, Train: 0.5249, Val: 0.5217\n",
      "Epoch: 020, Loss: 0.5691, Train: 0.6910, Val: 0.6958\n",
      "Epoch: 040, Loss: 0.5204, Train: 0.7673, Val: 0.7677\n",
      "Epoch: 060, Loss: 0.4593, Train: 0.7684, Val: 0.7723\n",
      "Epoch: 080, Loss: 0.4358, Train: 0.7904, Val: 0.7918\n",
      "Epoch: 100, Loss: 0.4253, Train: 0.8010, Val: 0.8015\n",
      "Epoch: 120, Loss: 0.4170, Train: 0.8057, Val: 0.8050\n",
      "Epoch: 140, Loss: 0.4090, Train: 0.8120, Val: 0.8092\n",
      "Epoch: 160, Loss: 0.4016, Train: 0.8133, Val: 0.8092\n",
      "Epoch: 180, Loss: 0.3955, Train: 0.8160, Val: 0.8150\n",
      "Epoch: 200, Loss: 0.3907, Train: 0.8168, Val: 0.8154\n",
      "tn, fp, fn, tp 1308 184 244 1142\n",
      "acc :0.8513\n",
      "f1 :0.8511\n",
      "auc :0.8503\n",
      "prec :0.8612\n",
      "recall :0.8240\n",
      "fpr :0.1233\n",
      "mi_f1 :0.8513\n",
      "ma_f1 :0.8508\n",
      "tn, fp, fn, tp 851 124 145 711\n",
      "acc :0.8531\n",
      "f1 :0.8530\n",
      "auc :0.8517\n",
      "prec :0.8515\n",
      "recall :0.8306\n",
      "fpr :0.1272\n",
      "mi_f1 :0.8531\n",
      "ma_f1 :0.8522\n",
      "Total labeled 897635\n",
      "Labeled node count for 3, 9: 33643\n",
      "Labeled node count for 3, 10: 1906\n",
      "Labeled node count for 3, 11: 1460\n",
      "Epoch: 000, Loss: 0.6941, Train: 0.4820, Val: 0.4842\n",
      "Epoch: 020, Loss: 0.5799, Train: 0.6447, Val: 0.6394\n",
      "Epoch: 040, Loss: 0.5405, Train: 0.7634, Val: 0.7652\n",
      "Epoch: 060, Loss: 0.4845, Train: 0.7647, Val: 0.7675\n",
      "Epoch: 080, Loss: 0.4449, Train: 0.7691, Val: 0.7708\n",
      "Epoch: 100, Loss: 0.4317, Train: 0.7985, Val: 0.7961\n",
      "Epoch: 120, Loss: 0.4230, Train: 0.8028, Val: 0.8016\n",
      "Epoch: 140, Loss: 0.4142, Train: 0.8100, Val: 0.8095\n",
      "Epoch: 160, Loss: 0.4049, Train: 0.8148, Val: 0.8148\n",
      "Epoch: 180, Loss: 0.3961, Train: 0.8165, Val: 0.8158\n",
      "Epoch: 200, Loss: 0.3892, Train: 0.8178, Val: 0.8167\n",
      "tn, fp, fn, tp 867 136 148 755\n",
      "acc :0.8510\n",
      "f1 :0.8509\n",
      "auc :0.8503\n",
      "prec :0.8474\n",
      "recall :0.8361\n",
      "fpr :0.1356\n",
      "mi_f1 :0.8510\n",
      "ma_f1 :0.8505\n",
      "tn, fp, fn, tp 791 134 90 445\n",
      "acc :0.8466\n",
      "f1 :0.8477\n",
      "auc :0.8435\n",
      "prec :0.7686\n",
      "recall :0.8318\n",
      "fpr :0.1449\n",
      "mi_f1 :0.8466\n",
      "ma_f1 :0.8374\n",
      "Total labeled 897635\n",
      "Labeled node count for 4, 10: 32652\n",
      "Labeled node count for 4, 11: 1530\n",
      "Labeled node count for 4, 12: 2044\n",
      "Epoch: 000, Loss: 0.7019, Train: 0.4907, Val: 0.4876\n",
      "Epoch: 020, Loss: 0.5751, Train: 0.6875, Val: 0.6802\n",
      "Epoch: 040, Loss: 0.5277, Train: 0.7644, Val: 0.7602\n",
      "Epoch: 060, Loss: 0.4698, Train: 0.7647, Val: 0.7597\n",
      "Epoch: 080, Loss: 0.4370, Train: 0.7853, Val: 0.7819\n",
      "Epoch: 100, Loss: 0.4263, Train: 0.8071, Val: 0.8057\n",
      "Epoch: 120, Loss: 0.4189, Train: 0.8086, Val: 0.8075\n",
      "Epoch: 140, Loss: 0.4115, Train: 0.8135, Val: 0.8135\n",
      "Epoch: 160, Loss: 0.4033, Train: 0.8157, Val: 0.8184\n",
      "Epoch: 180, Loss: 0.3960, Train: 0.8177, Val: 0.8194\n",
      "Epoch: 200, Loss: 0.3898, Train: 0.8180, Val: 0.8193\n",
      "tn, fp, fn, tp 812 147 90 481\n",
      "acc :0.8451\n",
      "f1 :0.8464\n",
      "auc :0.8445\n",
      "prec :0.7659\n",
      "recall :0.8424\n",
      "fpr :0.1533\n",
      "mi_f1 :0.8451\n",
      "ma_f1 :0.8375\n",
      "tn, fp, fn, tp 991 165 166 722\n",
      "acc :0.8381\n",
      "f1 :0.8381\n",
      "auc :0.8352\n",
      "prec :0.8140\n",
      "recall :0.8131\n",
      "fpr :0.1427\n",
      "mi_f1 :0.8381\n",
      "ma_f1 :0.8352\n"
     ]
    }
   ],
   "source": [
    "cuda_device = 0\n",
    "torch.manual_seed(42)\n",
    "from src.utils import score\n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['domain_node'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['domain_node'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for split in ['train_mask', 'val_mask']:\n",
    "        mask = data['domain_node'][split]\n",
    "        acc = (pred[mask] == data['domain_node'].y[mask]).sum() / mask.sum()\n",
    "        accs.append(float(acc))\n",
    "    return accs\n",
    "\n",
    "def experiment(model,start,end,test_list, model_type):\n",
    "    kg_path = lambda graph_name: f'../../data/{graph_name}'\n",
    "\n",
    "    dataset = tl.DNS(root=kg_path('DNS_2m'), start=start, end=end, test_list=test_list, balance_gt=False, domain_file='domains2.csv')\n",
    "    # data = to_homogeneous(dataset.train_data) # training data\n",
    "    data = dataset.train_data # training data\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        torch.cuda.set_device(cuda_device)\n",
    "\n",
    "        data, model = data.to(device), model.to(device)\n",
    "\n",
    "    with torch.no_grad():  # Initialize lazy modules.\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "    for epoch in range(0, 201):\n",
    "        loss = train(model, data, optimizer)\n",
    "        train_acc, val_acc = test(model,data)\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
    "                f'Val: {val_acc:.4f}')\n",
    "        \n",
    "    model.eval()\n",
    "    for index, test_data in enumerate(dataset.test_data):\n",
    "        # test_data = to_homogeneous(test_data)\n",
    "        test_data = test_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(test_data.x_dict, test_data.edge_index_dict).argmax(dim=-1)\n",
    "        mask = test_data['domain_node']['val_mask']\n",
    "        scores = score(pred[mask],test_data['domain_node'].y[mask])\n",
    "        with open(\"../../results_copy.csv\", \"a\") as logger:\n",
    "            logger.write(\"{},{},{},{},\".format(model_type,start,end,index))\n",
    "            logger.write(\",\".join(str(x) for x in scores.values()))\n",
    "            logger.write('\\n')\n",
    "\n",
    "\n",
    "        for metric, val in scores.items():\n",
    "            print(metric, ':{:.4f}'.format(val))\n",
    "    \n",
    "for model_type in ['hgt']:\n",
    "    for i in range(5):\n",
    "        # model_type='gcn'  \n",
    "        # data.x.size(1) \n",
    "        model = HGT(data, hidden_channels=64, out_channels=2, num_heads=8,\n",
    "                  num_layers=2)\n",
    "        experiment(model,i,i+6,[i+7,i+8], model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
