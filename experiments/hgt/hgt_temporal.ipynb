{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGT Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.nn import Linear\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src import temporal_loader_v2 as tl\n",
    "from src.utils import score\n",
    "from hgt_conv import HGTConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 2\n",
    "pyg.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, data, hidden_channels, out_channels, num_heads, num_layers, num_features=-1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in data.node_types:\n",
    "            self.lin_dict[node_type] = Linear(num_features, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(),\n",
    "                           num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, target_nodetype='domain_node'):\n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return self.lin(x_dict[target_nodetype])\n",
    "    \n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['domain_node'].train_mask\n",
    "    loss = F.cross_entropy(out[mask], data['domain_node'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict).argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for split in ['train_mask', 'val_mask']:\n",
    "        mask = data['domain_node'][split]\n",
    "        acc = (pred[mask] == data['domain_node'].y[mask]).sum() / mask.sum()\n",
    "        accs.append(float(acc))\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled 897635\n",
      "Labeled node count for 0, 6: 31778\n",
      "Labeled node count for 0, 7: 2610\n",
      "Labeled node count for 0, 8: 2083\n",
      "Epoch: 000, Loss: 0.6929, Train: 0.5514, Val: 0.5380\n",
      "Epoch: 020, Loss: 0.5718, Train: 0.6950, Val: 0.6875\n",
      "Epoch: 040, Loss: 0.5288, Train: 0.7644, Val: 0.7580\n",
      "Epoch: 060, Loss: 0.4724, Train: 0.7657, Val: 0.7574\n",
      "Epoch: 080, Loss: 0.4428, Train: 0.7739, Val: 0.7659\n",
      "Epoch: 100, Loss: 0.4316, Train: 0.7888, Val: 0.7816\n",
      "Epoch: 120, Loss: 0.4233, Train: 0.7994, Val: 0.7923\n",
      "Epoch: 140, Loss: 0.4153, Train: 0.8066, Val: 0.8030\n",
      "Epoch: 160, Loss: 0.4072, Train: 0.8119, Val: 0.8080\n",
      "Epoch: 180, Loss: 0.3998, Train: 0.8158, Val: 0.8131\n",
      "Epoch: 200, Loss: 0.3937, Train: 0.8161, Val: 0.8159\n",
      "tn, fp, fn, tp 1382 223 181 824\n",
      "acc :0.8452\n",
      "f1 :0.8458\n",
      "auc :0.8405\n",
      "prec :0.7870\n",
      "recall :0.8199\n",
      "fpr :0.1389\n",
      "mi_f1 :0.8452\n",
      "ma_f1 :0.8378\n",
      "tn, fp, fn, tp 1128 181 157 617\n",
      "acc :0.8377\n",
      "f1 :0.8382\n",
      "auc :0.8294\n",
      "prec :0.7732\n",
      "recall :0.7972\n",
      "fpr :0.1383\n",
      "mi_f1 :0.8377\n",
      "ma_f1 :0.8273\n",
      "Total labeled 897635\n",
      "Labeled node count for 1, 7: 32913\n",
      "Labeled node count for 1, 8: 2164\n",
      "Labeled node count for 1, 9: 2756\n",
      "Epoch: 000, Loss: 0.6923, Train: 0.5524, Val: 0.5506\n",
      "Epoch: 020, Loss: 0.5701, Train: 0.6793, Val: 0.6828\n",
      "Epoch: 040, Loss: 0.5200, Train: 0.7692, Val: 0.7659\n",
      "Epoch: 060, Loss: 0.4578, Train: 0.7715, Val: 0.7648\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61911/1135827397.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'hgt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_61911/1135827397.py\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(start, end, test_list, model_type)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_61911/2228294453.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, optimizer)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def experiment(start,end,test_list, model_type):\n",
    "    kg_path = lambda graph_name: f'../../data/{graph_name}'\n",
    "\n",
    "    dataset = tl.DNS(root=kg_path('DNS_2m'), start=start, end=end, test_list=test_list, balance_gt=False, domain_file='domains2.csv')\n",
    "    data = dataset.train_data # training data\n",
    "    \n",
    "    model = HGT(data, hidden_channels=64, out_channels=2, num_heads=8, num_layers=2)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        torch.cuda.set_device(cuda_device)\n",
    "\n",
    "        data, model = data.to(device), model.to(device)\n",
    "\n",
    "    with torch.no_grad():  # Initialize lazy modules.\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "    for epoch in range(0, 201):\n",
    "        loss = train(model, data, optimizer)\n",
    "        train_acc, val_acc = test(model,data)\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
    "                f'Val: {val_acc:.4f}')\n",
    "        \n",
    "    model.eval()\n",
    "    for index, test_data in enumerate(dataset.test_data):\n",
    "        test_data = test_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(test_data.x_dict, test_data.edge_index_dict).argmax(dim=-1)\n",
    "        mask = test_data['domain_node']['val_mask']\n",
    "        scores = score(pred[mask],test_data['domain_node'].y[mask])\n",
    "        with open(\"../../results_copy.csv\", \"a\") as logger:\n",
    "            logger.write(\"{},{},{},{},\".format(model_type,start,end,index))\n",
    "            logger.write(\",\".join(str(x) for x in scores.values()))\n",
    "            logger.write('\\n')\n",
    "\n",
    "\n",
    "        for metric, val in scores.items():\n",
    "            print(metric, ':{:.4f}'.format(val))\n",
    "    \n",
    "for model_type in ['hgt']:\n",
    "    for i in range(5):\n",
    "        experiment(i,i+6,[i+7,i+8], model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
