{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.nn import GCNConv, Linear\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src import temporal_loader_v2 as tl\n",
    "from src.utils import to_homogeneous, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 4\n",
    "pyg.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, dim=16, num_classes=2, num_layers=2, model_type='gcn'):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(num_features, dim)\n",
    "        self.gcs = torch.nn.ModuleList()\n",
    "        self.num_layers = num_layers\n",
    "        for i in range(1, num_layers):\n",
    "            conv = GCNConv(dim, dim)\n",
    "            self.gcs.append(conv)\n",
    "        self.lin = Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, data=None, save_embedding=False):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        for i in range(1, self.num_layers):\n",
    "            x = F.relu(self.gcs[i-1](x, edge_index))\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        return self.lin(x)\n",
    "    \n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    mask = data.train_mask\n",
    "    loss = F.cross_entropy(out[mask], data.y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    pred = model(data.x, data.edge_index).argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for split in ['train_mask', 'val_mask']:\n",
    "        mask = data[split]\n",
    "        acc = (pred[mask] == data.y[mask]).sum() / mask.sum()\n",
    "        accs.append(float(acc))\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled 897635\n",
      "Labeled node count for 0, 6: 31778\n",
      "Labeled node count for 0, 7: 2610\n",
      "Labeled node count for 0, 8: 2083\n",
      "Epoch: 000, Loss: 0.7043, Train: 0.7094, Val: 0.7169\n",
      "Epoch: 020, Loss: 0.5079, Train: 0.7903, Val: 0.7954\n",
      "Epoch: 040, Loss: 0.4562, Train: 0.8026, Val: 0.8066\n",
      "Epoch: 060, Loss: 0.4276, Train: 0.8075, Val: 0.8121\n",
      "Epoch: 080, Loss: 0.4195, Train: 0.8093, Val: 0.8118\n",
      "Epoch: 100, Loss: 0.4176, Train: 0.8101, Val: 0.8127\n",
      "Epoch: 120, Loss: 0.4156, Train: 0.8107, Val: 0.8131\n",
      "Epoch: 140, Loss: 0.4144, Train: 0.8112, Val: 0.8135\n",
      "Epoch: 160, Loss: 0.4123, Train: 0.8115, Val: 0.8132\n",
      "Epoch: 180, Loss: 0.4121, Train: 0.8115, Val: 0.8137\n",
      "Epoch: 200, Loss: 0.4127, Train: 0.8112, Val: 0.8132\n",
      "tn, fp, fn, tp 1307 298 159 846\n",
      "acc :0.8249\n",
      "f1 :0.8266\n",
      "auc :0.8281\n",
      "prec :0.7395\n",
      "recall :0.8418\n",
      "fpr :0.1857\n",
      "mi_f1 :0.8249\n",
      "ma_f1 :0.8193\n",
      "tn, fp, fn, tp 1059 250 116 658\n",
      "acc :0.8243\n",
      "f1 :0.8266\n",
      "auc :0.8296\n",
      "prec :0.7247\n",
      "recall :0.8501\n",
      "fpr :0.1910\n",
      "mi_f1 :0.8243\n",
      "ma_f1 :0.8175\n",
      "Total labeled 897635\n",
      "Labeled node count for 1, 7: 32913\n",
      "Labeled node count for 1, 8: 2164\n",
      "Labeled node count for 1, 9: 2756\n",
      "Epoch: 000, Loss: 0.6937, Train: 0.5603, Val: 0.5435\n",
      "Epoch: 020, Loss: 0.5091, Train: 0.7693, Val: 0.7689\n",
      "Epoch: 040, Loss: 0.4559, Train: 0.8037, Val: 0.7958\n",
      "Epoch: 060, Loss: 0.4228, Train: 0.8124, Val: 0.8031\n",
      "Epoch: 080, Loss: 0.4158, Train: 0.8136, Val: 0.8016\n",
      "Epoch: 100, Loss: 0.4141, Train: 0.8142, Val: 0.8028\n",
      "Epoch: 120, Loss: 0.4111, Train: 0.8141, Val: 0.8031\n",
      "Epoch: 140, Loss: 0.4099, Train: 0.8144, Val: 0.8022\n",
      "Epoch: 160, Loss: 0.4104, Train: 0.8144, Val: 0.8025\n",
      "Epoch: 180, Loss: 0.4090, Train: 0.8145, Val: 0.8023\n",
      "Epoch: 200, Loss: 0.4057, Train: 0.8144, Val: 0.8026\n",
      "tn, fp, fn, tp 1093 246 129 696\n",
      "acc :0.8267\n",
      "f1 :0.8285\n",
      "auc :0.8300\n",
      "prec :0.7389\n",
      "recall :0.8436\n",
      "fpr :0.1837\n",
      "mi_f1 :0.8267\n",
      "ma_f1 :0.8207\n",
      "tn, fp, fn, tp 1170 247 234 1105\n",
      "acc :0.8255\n",
      "f1 :0.8255\n",
      "auc :0.8255\n",
      "prec :0.8173\n",
      "recall :0.8252\n",
      "fpr :0.1743\n",
      "mi_f1 :0.8255\n",
      "ma_f1 :0.8254\n",
      "Total labeled 897635\n",
      "Labeled node count for 2, 8: 33022\n",
      "Labeled node count for 2, 9: 2878\n",
      "Labeled node count for 2, 10: 1831\n",
      "Epoch: 000, Loss: 0.6838, Train: 0.7055, Val: 0.7112\n",
      "Epoch: 020, Loss: 0.5009, Train: 0.7848, Val: 0.7823\n",
      "Epoch: 040, Loss: 0.4479, Train: 0.8041, Val: 0.8025\n",
      "Epoch: 060, Loss: 0.4249, Train: 0.8120, Val: 0.8141\n",
      "Epoch: 080, Loss: 0.4192, Train: 0.8123, Val: 0.8145\n",
      "Epoch: 100, Loss: 0.4129, Train: 0.8124, Val: 0.8137\n",
      "Epoch: 120, Loss: 0.4121, Train: 0.8129, Val: 0.8136\n",
      "Epoch: 140, Loss: 0.4080, Train: 0.8133, Val: 0.8137\n",
      "Epoch: 160, Loss: 0.4071, Train: 0.8135, Val: 0.8134\n",
      "Epoch: 180, Loss: 0.4109, Train: 0.8138, Val: 0.8136\n",
      "Epoch: 200, Loss: 0.4071, Train: 0.8134, Val: 0.8142\n",
      "tn, fp, fn, tp 1244 248 258 1128\n",
      "acc :0.8242\n",
      "f1 :0.8242\n",
      "auc :0.8238\n",
      "prec :0.8198\n",
      "recall :0.8139\n",
      "fpr :0.1662\n",
      "mi_f1 :0.8242\n",
      "ma_f1 :0.8239\n",
      "tn, fp, fn, tp 822 153 134 722\n",
      "acc :0.8433\n",
      "f1 :0.8433\n",
      "auc :0.8433\n",
      "prec :0.8251\n",
      "recall :0.8435\n",
      "fpr :0.1569\n",
      "mi_f1 :0.8433\n",
      "ma_f1 :0.8428\n",
      "Total labeled 897635\n",
      "Labeled node count for 3, 9: 33643\n",
      "Labeled node count for 3, 10: 1906\n",
      "Labeled node count for 3, 11: 1460\n",
      "Epoch: 000, Loss: 0.7039, Train: 0.5693, Val: 0.5777\n",
      "Epoch: 020, Loss: 0.5167, Train: 0.7800, Val: 0.7720\n",
      "Epoch: 040, Loss: 0.4542, Train: 0.8033, Val: 0.7995\n",
      "Epoch: 060, Loss: 0.4251, Train: 0.8097, Val: 0.8095\n",
      "Epoch: 080, Loss: 0.4181, Train: 0.8107, Val: 0.8109\n",
      "Epoch: 100, Loss: 0.4153, Train: 0.8116, Val: 0.8108\n",
      "Epoch: 120, Loss: 0.4142, Train: 0.8128, Val: 0.8120\n",
      "Epoch: 140, Loss: 0.4107, Train: 0.8129, Val: 0.8117\n",
      "Epoch: 160, Loss: 0.4093, Train: 0.8126, Val: 0.8117\n",
      "Epoch: 180, Loss: 0.4078, Train: 0.8132, Val: 0.8121\n",
      "Epoch: 200, Loss: 0.4081, Train: 0.8132, Val: 0.8124\n",
      "tn, fp, fn, tp 830 173 133 770\n",
      "acc :0.8395\n",
      "f1 :0.8396\n",
      "auc :0.8401\n",
      "prec :0.8165\n",
      "recall :0.8527\n",
      "fpr :0.1725\n",
      "mi_f1 :0.8395\n",
      "ma_f1 :0.8393\n",
      "tn, fp, fn, tp 749 176 95 440\n",
      "acc :0.8144\n",
      "f1 :0.8167\n",
      "auc :0.8161\n",
      "prec :0.7143\n",
      "recall :0.8224\n",
      "fpr :0.1903\n",
      "mi_f1 :0.8144\n",
      "ma_f1 :0.8057\n",
      "Total labeled 897635\n",
      "Labeled node count for 4, 10: 32652\n",
      "Labeled node count for 4, 11: 1530\n",
      "Labeled node count for 4, 12: 2044\n",
      "Epoch: 000, Loss: 0.7221, Train: 0.4824, Val: 0.4783\n",
      "Epoch: 020, Loss: 0.5129, Train: 0.7859, Val: 0.7888\n",
      "Epoch: 040, Loss: 0.4497, Train: 0.8020, Val: 0.8031\n",
      "Epoch: 060, Loss: 0.4229, Train: 0.8117, Val: 0.8133\n",
      "Epoch: 080, Loss: 0.4165, Train: 0.8122, Val: 0.8155\n",
      "Epoch: 100, Loss: 0.4108, Train: 0.8123, Val: 0.8161\n",
      "Epoch: 120, Loss: 0.4093, Train: 0.8127, Val: 0.8156\n",
      "Epoch: 140, Loss: 0.4065, Train: 0.8128, Val: 0.8158\n",
      "Epoch: 160, Loss: 0.4085, Train: 0.8129, Val: 0.8161\n",
      "Epoch: 180, Loss: 0.4057, Train: 0.8134, Val: 0.8170\n",
      "Epoch: 200, Loss: 0.4048, Train: 0.8139, Val: 0.8167\n",
      "tn, fp, fn, tp 782 177 98 473\n",
      "acc :0.8203\n",
      "f1 :0.8222\n",
      "auc :0.8219\n",
      "prec :0.7277\n",
      "recall :0.8284\n",
      "fpr :0.1846\n",
      "mi_f1 :0.8203\n",
      "ma_f1 :0.8126\n",
      "tn, fp, fn, tp 948 208 185 703\n",
      "acc :0.8077\n",
      "f1 :0.8080\n",
      "auc :0.8059\n",
      "prec :0.7717\n",
      "recall :0.7917\n",
      "fpr :0.1799\n",
      "mi_f1 :0.8077\n",
      "ma_f1 :0.8049\n"
     ]
    }
   ],
   "source": [
    "def experiment(start,end,test_list, model_type):\n",
    "    kg_path = lambda graph_name: f'../data/{graph_name}'\n",
    "\n",
    "    dataset = tl.DNS(root=kg_path('DNS_2m'), start=start, end=end, test_list=test_list, \n",
    "                     balance_gt=False, domain_file='domains2.csv')\n",
    "    data = to_homogeneous(dataset.train_data) # training data\n",
    "    \n",
    "    model = GNN(data.x.size(1), dim=64, num_classes=2, num_layers=2, model_type=model_type)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        torch.cuda.set_device(cuda_device)\n",
    "\n",
    "        data, model = data.to(device), model.to(device)\n",
    "\n",
    "    with torch.no_grad():  # Initialize lazy modules.\n",
    "        out = model(data.x, data.edge_index)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "    for epoch in range(0, 201):\n",
    "        loss = train(model, data, optimizer)\n",
    "        train_acc, val_acc = test(model,data)\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
    "                f'Val: {val_acc:.4f}')\n",
    "        \n",
    "    model.eval()\n",
    "    for index, test_data in enumerate(dataset.test_data):\n",
    "        test_data = to_homogeneous(test_data)\n",
    "        test_data = test_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(test_data.x, test_data.edge_index).argmax(dim=-1)\n",
    "        mask = test_data['val_mask']\n",
    "        scores = score(pred[mask],test_data.y[mask])\n",
    "        with open(\"results_copy.csv\", \"a\") as logger:\n",
    "            logger.write(\"{},{},{},{},\".format(model_type,start,end,index))\n",
    "            logger.write(\",\".join(str(x) for x in scores.values()))\n",
    "            logger.write('\\n')\n",
    "\n",
    "\n",
    "        for metric, val in scores.items():\n",
    "            print(metric, ':{:.4f}'.format(val))\n",
    "    \n",
    "for model_type in ['gcn']:\n",
    "    for i in range(5):\n",
    "        experiment(i,i+6,[i+7,i+8], model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
